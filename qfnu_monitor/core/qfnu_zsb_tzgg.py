#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç½‘ç«™ç›‘æ§æ¨¡å—æ¨¡æ¿
ç”¨äºå¿«é€Ÿåˆ›å»ºæ–°çš„ç½‘ç«™ç›‘æ§å™¨

ä½¿ç”¨æ–¹æ³•ï¼š
1. å¤åˆ¶æ­¤æ¨¡æ¿æ–‡ä»¶
2. ä¿®æ”¹ç±»åã€URLã€é€‰æ‹©å™¨ç­‰é…ç½®
3. æ ¹æ®ç½‘ç«™ç»“æ„è°ƒæ•´è§£æé€»è¾‘
4. æ·»åŠ åˆ°ä¸»ç¨‹åºä¸­
"""

import requests
import json
import os
from bs4 import BeautifulSoup
from qfnu_monitor.utils.feishu import feishu
from qfnu_monitor.utils.onebot import onebot_send_all
from qfnu_monitor.utils import logger


class WebsiteMonitorTemplate:
    """
    ç½‘ç«™ç›‘æ§æ¨¡æ¿ç±»

    éœ€è¦ä¿®æ”¹çš„é…ç½®é¡¹ï¼š
    - __init__ ä¸­çš„ URL å’Œæ–‡ä»¶å
    - get_notices ä¸­çš„é€‰æ‹©å™¨å’Œè§£æé€»è¾‘
    - push_to_* æ–¹æ³•ä¸­çš„æ¶ˆæ¯æ ‡é¢˜
    """

    def __init__(self, data_dir="data"):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨

        Args:
            data_dir (str): æ•°æ®å­˜å‚¨ç›®å½•
        """
        # ====== éœ€è¦ä¿®æ”¹çš„é…ç½® ======
        self.url = "https://example.com/notices"  # ç›®æ ‡ç½‘ç«™URL
        self.base_url = "https://example.com/"  # ç½‘ç«™åŸºç¡€URL
        self.site_name = "ç¤ºä¾‹ç½‘ç«™"  # ç½‘ç«™åç§°ï¼ˆç”¨äºæ—¥å¿—å’Œé€šçŸ¥ï¼‰
        self.data_file_prefix = "example"  # æ•°æ®æ–‡ä»¶å‰ç¼€
        # ===========================

        self.data_dir = data_dir
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
        # ç¡®ä¿å½’æ¡£ç›®å½•å­˜åœ¨
        self.archive_dir = os.path.join(self.data_dir, "archive")
        os.makedirs(self.archive_dir, exist_ok=True)

        # æ•°æ®æ–‡ä»¶è·¯å¾„
        self.data_file = os.path.join(
            self.data_dir, f"{self.data_file_prefix}_notices.json"
        )
        self.archive_file = os.path.join(
            self.archive_dir, f"{self.data_file_prefix}_notices_archive.json"
        )
        self.max_notices = 30  # æœ€å¤šä¿ç•™çš„é€šçŸ¥æ•°é‡ï¼Œåº”å¤§äºç½‘ç«™å…¬å‘Šæ•°é‡

    def get_html(self):
        """
        è·å–ç½‘é¡µHTMLå†…å®¹

        Returns:
            str: HTMLå†…å®¹
        """
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(self.url, headers=headers, timeout=10)
        response.encoding = "utf-8"
        return response.text

    def parse_html(self, html):
        """
        è§£æHTMLå†…å®¹

        Args:
            html (str): HTMLå†…å®¹

        Returns:
            BeautifulSoup: è§£æåçš„soupå¯¹è±¡
        """
        soup = BeautifulSoup(html, "html.parser")
        return soup

    def get_notices(self, soup):
        """
        ä»è§£æåçš„HTMLä¸­æå–å…¬å‘Šä¿¡æ¯

        âš ï¸ æ­¤æ–¹æ³•éœ€è¦æ ¹æ®ç›®æ ‡ç½‘ç«™çš„HTMLç»“æ„è¿›è¡Œä¿®æ”¹

        Args:
            soup (BeautifulSoup): è§£æåçš„soupå¯¹è±¡

        Returns:
            list: å…¬å‘Šåˆ—è¡¨ï¼Œæ¯ä¸ªå…¬å‘ŠåŒ…å« titleã€linkã€date å­—æ®µ
        """
        notices = []

        # ====== éœ€è¦æ ¹æ®ç½‘ç«™ç»“æ„ä¿®æ”¹çš„é€‰æ‹©å™¨ ======
        # ç¤ºä¾‹ï¼šé€šç”¨çš„å…¬å‘Šåˆ—è¡¨é€‰æ‹©å™¨
        notice_list = soup.select("ul li")  # ä¿®æ”¹ä¸ºå®é™…çš„é€‰æ‹©å™¨

        for item in notice_list:
            try:
                # æå–æ ‡é¢˜å’Œé“¾æ¥
                title_tag = item.select_one("a")  # ä¿®æ”¹ä¸ºå®é™…çš„é€‰æ‹©å™¨
                if not title_tag:
                    continue

                title = title_tag.get_text().strip()
                link = title_tag.get("href")

                # å¤„ç†ç›¸å¯¹é“¾æ¥
                if link and not link.startswith("http"):
                    link = self.base_url + link.lstrip("/")

                # æå–æ—¥æœŸ
                date_tag = item.select_one(".date")  # ä¿®æ”¹ä¸ºå®é™…çš„é€‰æ‹©å™¨
                date = date_tag.get_text().strip() if date_tag else ""

                # è¿‡æ»¤æ— æ•ˆæ•°æ®
                if title and link:
                    notices.append({"title": title, "link": link, "date": date})

            except Exception as e:
                logger.warning(f"è§£æå…¬å‘Šé¡¹æ—¶å‡ºé”™: {e}")
                continue
        # ========================================

        return notices

    def load_saved_notices(self):
        """
        åŠ è½½å·²ä¿å­˜çš„å…¬å‘Š

        Returns:
            list: å·²ä¿å­˜çš„å…¬å‘Šåˆ—è¡¨
        """
        if not os.path.exists(self.data_file) or os.path.getsize(self.data_file) == 0:
            logger.info(f"åˆå§‹åŒ–{self.site_name}å…¬å‘Šè®°å½•æ–‡ä»¶")
            return []

        try:
            with open(self.data_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–{self.site_name}å…¬å‘Šè®°å½•å¤±è´¥: {e}")
            return []

    def load_archived_notices(self):
        """
        åŠ è½½å·²å­˜æ¡£çš„å…¬å‘Š

        Returns:
            list: å·²å­˜æ¡£çš„å…¬å‘Šåˆ—è¡¨
        """
        if (
            not os.path.exists(self.archive_file)
            or os.path.getsize(self.archive_file) == 0
        ):
            return []

        try:
            with open(self.archive_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–{self.site_name}å…¬å‘Šå­˜æ¡£è®°å½•å¤±è´¥: {e}")
            return []

    def save_notices(self, notices):
        """
        ä¿å­˜å…¬å‘Šï¼Œåªä¿å­˜æœ€æ–°çš„max_noticesæ¡

        Args:
            notices (list): å…¬å‘Šåˆ—è¡¨
        """
        latest_notices = (
            notices[-self.max_notices :] if len(notices) > self.max_notices else notices
        )
        with open(self.data_file, "w", encoding="utf-8") as f:
            json.dump(latest_notices, f, ensure_ascii=False, indent=2)

        # å¦‚æœæœ‰è¶…è¿‡max_noticesçš„å…¬å‘Šï¼Œå½’æ¡£å¤šä½™çš„å…¬å‘Š
        if len(notices) > self.max_notices:
            self.archive_notices(notices[: -self.max_notices])

    def archive_notices(self, notices_to_archive):
        """
        å°†å…¬å‘Šå­˜æ¡£

        Args:
            notices_to_archive (list): éœ€è¦å­˜æ¡£çš„å…¬å‘Šåˆ—è¡¨
        """
        if not notices_to_archive:
            return

        archived_notices = self.load_archived_notices()
        all_archived = archived_notices + notices_to_archive

        with open(self.archive_file, "w", encoding="utf-8") as f:
            json.dump(all_archived, f, ensure_ascii=False, indent=2)

        logger.info(f"å·²å½’æ¡£{len(notices_to_archive)}æ¡å…¬å‘Šåˆ°{self.archive_file}")

    def append_new_notices(self, new_notices):
        """
        å°†æ–°å…¬å‘Šæ·»åŠ åˆ°å·²ä¿å­˜çš„å…¬å‘Šåˆ—è¡¨ä¸­

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        saved_notices = self.load_saved_notices()
        all_notices = saved_notices + new_notices
        self.save_notices(all_notices)

    def find_new_notices(self, current_notices, saved_notices):
        """
        æŸ¥æ‰¾æ–°å…¬å‘Š

        Args:
            current_notices (list): å½“å‰æŠ“å–çš„å…¬å‘Š
            saved_notices (list): å·²ä¿å­˜çš„å…¬å‘Š

        Returns:
            list: æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not saved_notices:
            return current_notices

        saved_titles = {notice["title"] for notice in saved_notices}
        return [
            notice for notice in current_notices if notice["title"] not in saved_titles
        ]

    def push_to_feishu(self, new_notices):
        """
        æ¨é€æ–°å…¬å‘Šåˆ°é£ä¹¦

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not new_notices:
            return

        # ====== å¯ä»¥ä¿®æ”¹æ¶ˆæ¯æ ¼å¼ ======
        title = f"ğŸ“¢ {self.site_name}æœ‰{len(new_notices)}æ¡æ–°å…¬å‘Š"
        content = ""

        for i, notice in enumerate(new_notices, 1):
            content += f"ã€{i}ã€‘{notice['title']}\n"
            content += f"ğŸ“… {notice['date']}\n"
            content += f"ğŸ”— {notice['link']}\n\n"
        # ============================

        feishu(title, content)

    def push_to_onebot(self, new_notices):
        """
        é€šè¿‡OneBotå‘é€æ–°å…¬å‘Šé€šçŸ¥

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not new_notices:
            return

        # ====== å¯ä»¥ä¿®æ”¹æ¶ˆæ¯æ ¼å¼ ======
        message = f"ğŸ“¢ {self.site_name}æœ‰{len(new_notices)}æ¡æ–°å…¬å‘Š\n\n"

        for i, notice in enumerate(new_notices, 1):
            message += f"ã€{i}ã€‘{notice['title']}\n"
            message += f"ğŸ“… {notice['date']}\n"
            message += f"ğŸ”— {notice['link']}\n\n"
        # ============================

        # å‘é€åˆ°æ‰€æœ‰é…ç½®çš„ç¾¤ç»„
        result = onebot_send_all(message)

        if "error" in result:
            logger.error(f"OneBotå‘é€å¤±è´¥: {result['error']}")
        else:
            logger.info(f"OneBotå‘é€æˆåŠŸ: {result.get('success_count', 0)} ä¸ªç¾¤ç»„")

    def push_notifications(self, new_notices):
        """
        æ¨é€é€šçŸ¥åˆ°æ‰€æœ‰é…ç½®çš„å¹³å°

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not new_notices:
            return

        # æ¨é€åˆ°é£ä¹¦
        try:
            self.push_to_feishu(new_notices)
        except Exception as e:
            logger.error(f"é£ä¹¦æ¨é€å¤±è´¥: {e}")

        # æ¨é€åˆ°OneBotç¾¤ç»„
        try:
            self.push_to_onebot(new_notices)
        except Exception as e:
            logger.error(f"OneBotæ¨é€å¤±è´¥: {e}")

    def monitor(self):
        """
        æ‰§è¡Œç›‘æ§é€»è¾‘
        """
        try:
            # è·å–å½“å‰å…¬å‘Š
            html = self.get_html()
            soup = self.parse_html(html)
            current_notices = self.get_notices(soup)

            if not current_notices:
                logger.warning(f"æœªä»{self.site_name}è·å–åˆ°ä»»ä½•å…¬å‘Š")
                return

            # åŠ è½½å·²ä¿å­˜çš„å…¬å‘Š
            saved_notices = self.load_saved_notices()

            # æ£€æŸ¥æ˜¯å¦ä¸ºåˆå§‹åŒ–ï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œï¼‰
            is_first_run = not saved_notices

            # æŸ¥æ‰¾æ–°å…¬å‘Š
            new_notices = self.find_new_notices(current_notices, saved_notices)

            if new_notices:
                if is_first_run:
                    # ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œåªåˆå§‹åŒ–æ•°æ®ï¼Œä¸æ¨é€æ¶ˆæ¯
                    logger.info(
                        f"é¦–æ¬¡è¿è¡Œ{self.site_name}ç›‘æ§å™¨ï¼Œåˆå§‹åŒ–{len(new_notices)}æ¡å…¬å‘Šæ•°æ®ï¼Œä¸æ¨é€æ¶ˆæ¯"
                    )
                    # ç›´æ¥ä¿å­˜æ‰€æœ‰å½“å‰å…¬å‘Šä½œä¸ºåˆå§‹æ•°æ®
                    self.save_notices(current_notices)
                else:
                    # éé¦–æ¬¡è¿è¡Œï¼Œæ­£å¸¸æ¨é€æ–°å…¬å‘Š
                    logger.info(f"ä»{self.site_name}å‘ç°{len(new_notices)}æ¡æ–°å…¬å‘Š")
                    self.push_notifications(new_notices)
                    # æ›´æ–°ä¿å­˜çš„å…¬å‘Šï¼Œæ·»åŠ æ–°å…¬å‘Šè€Œä¸è¦†ç›–å·²æœ‰å…¬å‘Š
                    self.append_new_notices(new_notices)
            else:
                logger.info(f"{self.site_name}æ²¡æœ‰æ–°å…¬å‘Š")

        except Exception as e:
            logger.error(f"{self.site_name}ç›‘æ§è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")

    def run(self):
        """
        è¿è¡Œç›‘æ§å™¨
        """
        logger.info(f"å¼€å§‹ç›‘æ§{self.site_name}")
        self.monitor()


# =============================================
# ä½¿ç”¨ç¤ºä¾‹ï¼šåˆ›å»ºå…·ä½“çš„ç›‘æ§å™¨
# =============================================


class ExampleUniversityMonitor(WebsiteMonitorTemplate):
    """
    ç¤ºä¾‹å¤§å­¦å®˜ç½‘ç›‘æ§å™¨
    ç»§æ‰¿æ¨¡æ¿ç±»å¹¶ä¿®æ”¹ç‰¹å®šé…ç½®
    """

    def __init__(self, data_dir="data"):
        super().__init__(data_dir)

        # é‡å†™é…ç½®
        self.url = "https://example-university.edu.cn/news"
        self.base_url = "https://example-university.edu.cn/"
        self.site_name = "ç¤ºä¾‹å¤§å­¦å®˜ç½‘"
        self.data_file_prefix = "example_university"

    def get_notices(self, soup):
        """
        é‡å†™å…¬å‘Šè§£ææ–¹æ³•ä»¥é€‚åº”å…·ä½“ç½‘ç«™ç»“æ„
        """
        notices = []

        # æ ¹æ®å®é™…ç½‘ç«™ç»“æ„ä¿®æ”¹é€‰æ‹©å™¨
        notice_list = soup.select("div.news-list .news-item")

        for item in notice_list:
            try:
                title_tag = item.select_one("h3 a")
                if not title_tag:
                    continue

                title = title_tag.get_text().strip()
                link = title_tag.get("href")

                if link and not link.startswith("http"):
                    link = self.base_url + link.lstrip("/")

                date_tag = item.select_one(".news-date")
                date = date_tag.get_text().strip() if date_tag else ""

                if title and link:
                    notices.append({"title": title, "link": link, "date": date})

            except Exception as e:
                logger.warning(f"è§£æ{self.site_name}å…¬å‘Šé¡¹æ—¶å‡ºé”™: {e}")
                continue

        return notices


# =============================================
# æµ‹è¯•ä»£ç 
# =============================================


def main():
    """
    æµ‹è¯•å‡½æ•°
    """
    print("ç½‘ç«™ç›‘æ§æ¨¡æ¿æµ‹è¯•")
    print("=" * 50)

    # æµ‹è¯•æ¨¡æ¿ç±»ï¼ˆä¼šå¤±è´¥ï¼Œå› ä¸ºURLæ˜¯ç¤ºä¾‹ï¼‰
    try:
        monitor = WebsiteMonitorTemplate()
        print(f"åˆ›å»ºç›‘æ§å™¨: {monitor.site_name}")
        print(f"ç›®æ ‡URL: {monitor.url}")
        print(f"æ•°æ®æ–‡ä»¶: {monitor.data_file}")

        # ä¸å®é™…è¿è¡Œï¼Œåªæ¼”ç¤ºé…ç½®
        print("\né…ç½®æ£€æŸ¥å®Œæˆï¼")
        print("ä½¿ç”¨æ­¥éª¤ï¼š")
        print("1. å¤åˆ¶æ­¤æ¨¡æ¿æ–‡ä»¶")
        print("2. ä¿®æ”¹ __init__ æ–¹æ³•ä¸­çš„é…ç½®")
        print("3. æ ¹æ®ç›®æ ‡ç½‘ç«™è°ƒæ•´ get_notices æ–¹æ³•")
        print("4. æµ‹è¯•å¹¶æ·»åŠ åˆ°ä¸»ç¨‹åº")

    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹å‡ºé”™ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰: {e}")


if __name__ == "__main__":
    main()
