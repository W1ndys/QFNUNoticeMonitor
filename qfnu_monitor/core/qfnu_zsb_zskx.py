#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ›²é˜œå¸ˆèŒƒå¤§å­¦æ‹›ç”ŸåŠæ‹›ç”Ÿå¿«è®¯ç›‘æ§æ¨¡å—
é€šè¿‡APIæ¥å£è·å–æ‹›ç”Ÿå¿«è®¯ä¿¡æ¯
"""

import requests
import json
import os
import time
from datetime import datetime
from qfnu_monitor.utils.feishu import feishu
from qfnu_monitor.utils.onebot import onebot_send_all
from qfnu_monitor.utils import logger


class QFNUZSBZSKXMonitor:
    """
    æ›²é˜œå¸ˆèŒƒå¤§å­¦æ‹›ç”ŸåŠæ‹›ç”Ÿå¿«è®¯ç›‘æ§å™¨
    é€šè¿‡POST APIæ¥å£è·å–æ‹›ç”Ÿå¿«è®¯æ•°æ®
    """

    def __init__(self, data_dir="data"):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨

        Args:
            data_dir (str): æ•°æ®å­˜å‚¨ç›®å½•
        """
        self.api_url = "https://zsb.qfnu.edu.cn/f/newsCenter/ajax_category_article_list"
        self.base_url = "https://zsb.qfnu.edu.cn"
        self.site_name = "æ›²å¸ˆå¤§æ‹›ç”ŸåŠæ‹›ç”Ÿå¿«è®¯"
        self.data_file_prefix = "zsb_zskx"

        # APIè¯·æ±‚å‚æ•°
        self.category_id = "e8659322e16240d296178402510b34f2"  # æ‹›ç”Ÿå¿«è®¯åˆ†ç±»ID
        self.page_size = 20  # æ¯æ¬¡è·å–çš„æ–‡ç« æ•°é‡

        self.data_dir = data_dir
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
        # ç¡®ä¿å½’æ¡£ç›®å½•å­˜åœ¨
        self.archive_dir = os.path.join(self.data_dir, "archive")
        os.makedirs(self.archive_dir, exist_ok=True)

        # æ•°æ®æ–‡ä»¶è·¯å¾„
        self.data_file = os.path.join(
            self.data_dir, f"{self.data_file_prefix}_notices.json"
        )
        self.archive_file = os.path.join(
            self.archive_dir, f"{self.data_file_prefix}_notices_archive.json"
        )
        self.max_notices = 50  # æœ€å¤šä¿ç•™çš„é€šçŸ¥æ•°é‡

    def get_api_data(self):
        """
        é€šè¿‡APIè·å–æ‹›ç”Ÿå¿«è®¯æ•°æ®

        Returns:
            dict: APIè¿”å›çš„JSONæ•°æ®
        """
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = str(int(time.time() * 1000))

        # è¯·æ±‚å¤´
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
            "Accept-Encoding": "gzip, deflate, br, zstd",
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
            "sec-ch-ua-platform": '"Windows"',
            "sec-ch-ua": '"Not)A;Brand";v="8", "Chromium";v="138", "Google Chrome";v="138"',
            "Csrf-Token": "T3IWIIT",
            "sec-ch-ua-mobile": "?0",
            "X-Requested-With": "XMLHttpRequest",
            "X-Requested-Time": timestamp,
            "Origin": "https://zsb.qfnu.edu.cn",
            "Sec-Fetch-Site": "same-origin",
            "Sec-Fetch-Mode": "cors",
            "Sec-Fetch-Dest": "empty",
            "Referer": "https://zsb.qfnu.edu.cn/",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        }

        # è¯·æ±‚æ•°æ®
        data = {"categoryId": self.category_id, "pageSize": str(self.page_size)}

        # æ·»åŠ æ—¶é—´æˆ³å‚æ•°åˆ°URL
        url_with_ts = f"{self.api_url}?ts={timestamp}"

        response = requests.post(url_with_ts, headers=headers, data=data, timeout=10)
        response.encoding = "utf-8"

        return response.json()

    def parse_api_data(self, api_data):
        """
        è§£æAPIè¿”å›çš„æ•°æ®

        Args:
            api_data (dict): APIè¿”å›çš„JSONæ•°æ®

        Returns:
            list: å…¬å‘Šåˆ—è¡¨ï¼Œæ¯ä¸ªå…¬å‘ŠåŒ…å« titleã€linkã€dateã€idã€description å­—æ®µ
        """
        notices = []

        try:
            if api_data.get("state") != 1:
                logger.error(f"APIè¿”å›é”™è¯¯: {api_data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                return notices

            data = api_data.get("data", [])
            if not data:
                logger.warning("APIè¿”å›çš„dataä¸ºç©º")
                return notices

            # è·å–ç¬¬ä¸€ä¸ªåˆ†ç±»çš„å†…å®¹åˆ—è¡¨
            content_list = data[0].get("contentList", [])

            for item in content_list:
                try:
                    # æå–åŸºæœ¬ä¿¡æ¯
                    notice_id = item.get("id", "")
                    title = item.get("title", "").strip()

                    # æ„å»ºé“¾æ¥
                    url = item.get("url", "")
                    link = ""
                    if url:
                        if url.startswith("http"):
                            link = url
                        else:
                            link = self.base_url + url

                    # å¤„ç†å¤–éƒ¨é“¾æ¥
                    if item.get("isExternalLink", False):
                        external_url = item.get("externalLinkUrl", "")
                        if external_url:
                            link = self.base_url + external_url

                    # è½¬æ¢å‘å¸ƒæ—¶é—´
                    release_date = item.get("releaseDate", 0)
                    if release_date:
                        # æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸå­—ç¬¦ä¸²
                        date = datetime.fromtimestamp(release_date / 1000).strftime(
                            "%Y-%m-%d"
                        )
                    else:
                        date = ""

                    # å…¶ä»–ä¿¡æ¯
                    description = item.get("description", "").strip()
                    publisher = item.get("publisher", "")
                    hits = item.get("hits", 0)
                    is_new = item.get("isNew", False)

                    # è¿‡æ»¤æ— æ•ˆæ•°æ®
                    if title and notice_id:
                        notices.append(
                            {
                                "id": notice_id,
                                "title": title,
                                "link": link,
                                "date": date,
                                "description": description,
                                "publisher": publisher,
                                "hits": hits,
                                "is_new": is_new,
                                "release_timestamp": release_date,
                            }
                        )

                except Exception as e:
                    logger.warning(f"è§£æå•ä¸ªæ‹›ç”Ÿå¿«è®¯é¡¹æ—¶å‡ºé”™: {e}")
                    continue

        except Exception as e:
            logger.error(f"è§£æAPIæ•°æ®æ—¶å‡ºé”™: {e}")

        return notices

    def load_saved_notices(self):
        """
        åŠ è½½å·²ä¿å­˜çš„å…¬å‘Š

        Returns:
            list: å·²ä¿å­˜çš„å…¬å‘Šåˆ—è¡¨
        """
        if not os.path.exists(self.data_file) or os.path.getsize(self.data_file) == 0:
            logger.info(f"åˆå§‹åŒ–{self.site_name}å…¬å‘Šè®°å½•æ–‡ä»¶")
            return []

        try:
            with open(self.data_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–{self.site_name}å…¬å‘Šè®°å½•å¤±è´¥: {e}")
            return []

    def load_archived_notices(self):
        """
        åŠ è½½å·²å­˜æ¡£çš„å…¬å‘Š

        Returns:
            list: å·²å­˜æ¡£çš„å…¬å‘Šåˆ—è¡¨
        """
        if (
            not os.path.exists(self.archive_file)
            or os.path.getsize(self.archive_file) == 0
        ):
            return []

        try:
            with open(self.archive_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–{self.site_name}å…¬å‘Šå­˜æ¡£è®°å½•å¤±è´¥: {e}")
            return []

    def save_notices(self, notices):
        """
        ä¿å­˜å…¬å‘Šï¼Œåªä¿å­˜æœ€æ–°çš„max_noticesæ¡

        Args:
            notices (list): å…¬å‘Šåˆ—è¡¨
        """
        latest_notices = (
            notices[-self.max_notices :] if len(notices) > self.max_notices else notices
        )
        with open(self.data_file, "w", encoding="utf-8") as f:
            json.dump(latest_notices, f, ensure_ascii=False, indent=2)

        # å¦‚æœæœ‰è¶…è¿‡max_noticesçš„å…¬å‘Šï¼Œå½’æ¡£å¤šä½™çš„å…¬å‘Š
        if len(notices) > self.max_notices:
            self.archive_notices(notices[: -self.max_notices])

    def archive_notices(self, notices_to_archive):
        """
        å°†å…¬å‘Šå­˜æ¡£

        Args:
            notices_to_archive (list): éœ€è¦å­˜æ¡£çš„å…¬å‘Šåˆ—è¡¨
        """
        if not notices_to_archive:
            return

        archived_notices = self.load_archived_notices()
        all_archived = archived_notices + notices_to_archive

        with open(self.archive_file, "w", encoding="utf-8") as f:
            json.dump(all_archived, f, ensure_ascii=False, indent=2)

        logger.info(f"å·²å½’æ¡£{len(notices_to_archive)}æ¡å…¬å‘Šåˆ°{self.archive_file}")

    def append_new_notices(self, new_notices):
        """
        å°†æ–°å…¬å‘Šæ·»åŠ åˆ°å·²ä¿å­˜çš„å…¬å‘Šåˆ—è¡¨ä¸­

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        saved_notices = self.load_saved_notices()
        all_notices = saved_notices + new_notices
        self.save_notices(all_notices)

    def find_new_notices(self, current_notices, saved_notices):
        """
        æŸ¥æ‰¾æ–°å…¬å‘Šï¼ˆåŸºäºIDï¼‰

        Args:
            current_notices (list): å½“å‰æŠ“å–çš„å…¬å‘Š
            saved_notices (list): å·²ä¿å­˜çš„å…¬å‘Š

        Returns:
            list: æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not saved_notices:
            return current_notices

        saved_ids = {notice["id"] for notice in saved_notices}
        return [notice for notice in current_notices if notice["id"] not in saved_ids]

    def push_to_feishu(self, new_notices):
        """
        æ¨é€æ–°å…¬å‘Šåˆ°é£ä¹¦

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not new_notices:
            return

        title = f"ğŸ“¢ {self.site_name}æœ‰{len(new_notices)}æ¡æ–°å…¬å‘Š"
        content = ""

        for i, notice in enumerate(new_notices, 1):
            content += f"ã€{i}ã€‘{notice['title']}\n"
            content += f"ğŸ“… å‘å¸ƒæ—¶é—´ï¼š{notice['date']}\n"
            if notice.get("publisher"):
                content += f"ğŸ‘¤ å‘å¸ƒè€…ï¼š{notice['publisher']}\n"
            if notice.get("hits"):
                content += f"ğŸ‘ï¸ æµè§ˆé‡ï¼š{notice['hits']}\n"
            if notice.get("is_new"):
                content += f"ğŸ†• æœ€æ–°å…¬å‘Š\n"
            if notice.get("description"):
                # æˆªå–æè¿°å‰100ä¸ªå­—ç¬¦
                desc = (
                    notice["description"][:100] + "..."
                    if len(notice["description"]) > 100
                    else notice["description"]
                )
                content += f"ğŸ“ ç®€ä»‹ï¼š{desc}\n"
            content += f"ğŸ”— é“¾æ¥ï¼š{notice['link']}\n\n"

        feishu(title, content)

    def push_to_onebot(self, new_notices):
        """
        é€šè¿‡OneBotå‘é€æ–°å…¬å‘Šé€šçŸ¥

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not new_notices:
            return

        message = f"ğŸ“¢ {self.site_name}æœ‰{len(new_notices)}æ¡æ–°å…¬å‘Š\n\n"

        for i, notice in enumerate(new_notices, 1):
            message += f"ã€{i}ã€‘{notice['title']}\n"
            message += f"ğŸ“… å‘å¸ƒæ—¶é—´ï¼š{notice['date']}\n"
            if notice.get("publisher"):
                message += f"ğŸ‘¤ å‘å¸ƒè€…ï¼š{notice['publisher']}\n"
            if notice.get("hits"):
                message += f"ğŸ‘ï¸ æµè§ˆé‡ï¼š{notice['hits']}\n"
            if notice.get("is_new"):
                message += f"ğŸ†• æœ€æ–°å…¬å‘Š\n"
            if notice.get("description"):
                # æˆªå–æè¿°å‰80ä¸ªå­—ç¬¦
                desc = (
                    notice["description"][:80] + "..."
                    if len(notice["description"]) > 80
                    else notice["description"]
                )
                message += f"ğŸ“ ç®€ä»‹ï¼š{desc}\n"
            message += f"ğŸ”— {notice['link']}\n\n"

        # å‘é€åˆ°æ‰€æœ‰é…ç½®çš„ç¾¤ç»„
        result = onebot_send_all(message)

        if "error" in result:
            logger.error(f"OneBotå‘é€å¤±è´¥: {result['error']}")
        else:
            logger.info(f"OneBotå‘é€æˆåŠŸ: {result.get('success_count', 0)} ä¸ªç¾¤ç»„")

    def push_notifications(self, new_notices):
        """
        æ¨é€é€šçŸ¥åˆ°æ‰€æœ‰é…ç½®çš„å¹³å°

        Args:
            new_notices (list): æ–°å…¬å‘Šåˆ—è¡¨
        """
        if not new_notices:
            return

        # æ¨é€åˆ°é£ä¹¦
        try:
            self.push_to_feishu(new_notices)
        except Exception as e:
            logger.error(f"é£ä¹¦æ¨é€å¤±è´¥: {e}")

        # æ¨é€åˆ°OneBotç¾¤ç»„
        try:
            self.push_to_onebot(new_notices)
        except Exception as e:
            logger.error(f"OneBotæ¨é€å¤±è´¥: {e}")

    def monitor(self):
        """
        æ‰§è¡Œç›‘æ§é€»è¾‘
        """
        try:
            # è·å–å½“å‰å…¬å‘Š
            api_data = self.get_api_data()
            current_notices = self.parse_api_data(api_data)

            if not current_notices:
                logger.warning(f"æœªä»{self.site_name}è·å–åˆ°ä»»ä½•å…¬å‘Š")
                return

            logger.info(f"ä»{self.site_name}è·å–åˆ°{len(current_notices)}æ¡å…¬å‘Š")

            # åŠ è½½å·²ä¿å­˜çš„å…¬å‘Š
            saved_notices = self.load_saved_notices()

            # æŸ¥æ‰¾æ–°å…¬å‘Š
            new_notices = self.find_new_notices(current_notices, saved_notices)

            if new_notices:
                logger.info(f"ä»{self.site_name}å‘ç°{len(new_notices)}æ¡æ–°å…¬å‘Š")
                self.push_notifications(new_notices)
                # æ›´æ–°ä¿å­˜çš„å…¬å‘Šï¼Œæ·»åŠ æ–°å…¬å‘Šè€Œä¸è¦†ç›–å·²æœ‰å…¬å‘Š
                self.append_new_notices(new_notices)
            else:
                logger.info(f"{self.site_name}æ²¡æœ‰æ–°å…¬å‘Š")

        except Exception as e:
            logger.error(f"{self.site_name}ç›‘æ§è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")

    def run(self):
        """
        è¿è¡Œç›‘æ§å™¨
        """
        logger.info(f"å¼€å§‹ç›‘æ§{self.site_name}")
        self.monitor()


def main():
    """
    æµ‹è¯•å‡½æ•°
    """
    print("æ›²é˜œå¸ˆèŒƒå¤§å­¦æ‹›ç”ŸåŠæ‹›ç”Ÿå¿«è®¯ç›‘æ§å™¨æµ‹è¯•")
    print("=" * 50)

    try:
        monitor = QFNUZSBZSKXMonitor()
        print(f"åˆ›å»ºç›‘æ§å™¨: {monitor.site_name}")
        print(f"APIåœ°å€: {monitor.api_url}")
        print(f"æ•°æ®æ–‡ä»¶: {monitor.data_file}")
        print(f"åˆ†ç±»ID: {monitor.category_id}")

        # æµ‹è¯•APIè°ƒç”¨
        print("\næµ‹è¯•APIè°ƒç”¨...")
        api_data = monitor.get_api_data()
        print(f"APIè°ƒç”¨çŠ¶æ€: {api_data.get('state', 'unknown')}")
        print(f"APIè¿”å›æ¶ˆæ¯: {api_data.get('msg', 'unknown')}")

        notices = monitor.parse_api_data(api_data)
        print(f"è§£æåˆ°{len(notices)}æ¡æ‹›ç”Ÿå¿«è®¯")

        if notices:
            print("\næœ€æ–°å‡ æ¡å…¬å‘Š:")
            for i, notice in enumerate(notices[:3], 1):
                print(f"{i}. {notice['title']}")
                print(f"   æ—¥æœŸ: {notice['date']}")
                print(f"   é“¾æ¥: {notice['link']}")
                print()

    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")


if __name__ == "__main__":
    main()
